{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "from scipy.special import comb\n",
    "import math\n",
    "from enum import Enum\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Any, List, Dict, Set, Tuple\n",
    "import time\n",
    "import sys, os\n",
    "#TODO: Mantener una consistencia entre el Camel Cases o el Snake Case, revisar que se usa en Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Digraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isLeaf(node, dag : nx.DiGraph):\n",
    "    return dag.out_degree(node) == 0\n",
    "\n",
    "def isRoot(node, dag : nx.DiGraph):\n",
    "    return dag.in_degree(node) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify the nodes in the DAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class NodeState(Enum):\n",
    "    ANCESTOR = 1\n",
    "    DESCENDANT = 2\n",
    "    UNRELATED = 3\n",
    "    FEATURE = 4\n",
    "\n",
    "\n",
    "#Classify the nodes into the category descendants, ancestors and unrelated. \n",
    "\n",
    "def classifyNodes(dag: nx.DiGraph, x_i : Any, nodes_classification : Dict[Any, NodeState]):\n",
    "    ancestors = nx.ancestors(dag, x_i)\n",
    "    descendants = nx.descendants(dag, x_i)\n",
    "    unrelated_roots = []\n",
    "    for node in dag.nodes():\n",
    "        if node in ancestors:\n",
    "            nodes_classification[node] = NodeState.ANCESTOR\n",
    "        elif node in descendants:\n",
    "            nodes_classification[node] = NodeState.DESCENDANT\n",
    "        elif node == x_i:\n",
    "            nodes_classification[node] = NodeState.FEATURE\n",
    "        else:\n",
    "            nodes_classification[node] = NodeState.UNRELATED\n",
    "            parents =  list(dag.predecessors(node))\n",
    "            parentIsAncestor = (parents[0] in ancestors) if len(parents) != 0 else False\n",
    "            if isRoot(node, dag) or parentIsAncestor:\n",
    "                unrelated_roots.append(node)\n",
    "\n",
    "\n",
    "    return unrelated_roots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equivalence Class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodePosition:\n",
    "\n",
    "    def __init__(self, node_name, appears_after_xi : bool) -> None:\n",
    "        self.node_name = node_name\n",
    "        self.appears_after_xi = appears_after_xi\n",
    "        self.relative_position = 'After' if appears_after_xi else 'Before'\n",
    "\n",
    "    def isBefore(self):\n",
    "        return not self.appears_after_xi\n",
    "    \n",
    "    def nodeName(self):\n",
    "        return self.node_name\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"({self.node_name}, {self.relative_position})\"\n",
    "\n",
    "class EquivalenceClass:\n",
    "\n",
    "    def __init__(self, unrelated_node_position : List[NodePosition], left_topo=1, right_topo=1):\n",
    "        self.before = self.obtainNodesBefore(unrelated_node_position)\n",
    "        self.after = self.obtainNodesAfter(unrelated_node_position)\n",
    "        self.left_topo = left_topo\n",
    "        self.right_topo = right_topo\n",
    "        if len(unrelated_node_position) != 0:\n",
    "            self.parent = list(unrelated_node_position)[0].nodeName()\n",
    "\n",
    "    def topologicalSort(self, feature_node = 'Feature Node'):\n",
    "        return self.before + [feature_node] + self.after\n",
    "\n",
    "    def obtainNodesBefore(self, posi):\n",
    "        positions = filter(lambda node_pos : node_pos.isBefore(), posi)\n",
    "        return list(map(lambda p : p.nodeName(),  positions))\n",
    "    \n",
    "    def obtainNodesAfter(self, posi):\n",
    "        positions = filter(lambda node_pos : not node_pos.isBefore(), posi)\n",
    "        return list(map(lambda p : p.nodeName(),  positions))\n",
    "    \n",
    "    def allNodes(self):\n",
    "        beforeAsPosition = list(map(lambda node : NodePosition(node, False), self.before))\n",
    "        afterAsPosition = list(map(lambda node : NodePosition(node, True), self.after))\n",
    "        return beforeAsPosition + afterAsPosition\n",
    "        \n",
    "    def nodes_after(self): #The nodes after x_i\n",
    "        return self.after\n",
    "\n",
    "    def nodes_before(self): #The nodes before x_i\n",
    "        return self.before\n",
    "    \n",
    "    def num_nodes_before(self): \n",
    "        return len(self.before)\n",
    "    \n",
    "    def num_nodes_after(self):\n",
    "        return len(self.after)\n",
    "    \n",
    "    def classSize(self): #Number of topological orders\n",
    "        return self.left_topo * self.right_topo\n",
    "    \n",
    "    def __str__(self):\n",
    "        \n",
    "        return f\"Equivalence Class (TopoSort={self.topologicalSort()}, Size={self.classSize()})\"\n",
    "    \n",
    "    def addParent(self, parent : Any):\n",
    "        self.before =  [parent] + self.before\n",
    "        self.parent = parent\n",
    "\n",
    "    def addParentToRigth(self, parent : Any):\n",
    "        self.after =  [parent] + self.after\n",
    "        self.parent = parent\n",
    "\n",
    "    def addAncestors(self, nodes : List[Any]):\n",
    "        self.before =  nodes + self.before\n",
    "\n",
    "    def classParent(self):\n",
    "        return self.parent\n",
    "\n",
    "    def addLeftTopo(self, leftTopos : int):\n",
    "        self.left_topo *= leftTopos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Posible Orderings Formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multinomial_coefficient(args) -> int:\n",
    "    n = sum(args)\n",
    "    coeff = 1\n",
    "    for k in args:\n",
    "        coeff *= comb(n, k, exact=True)\n",
    "        n -= k\n",
    "    return int(coeff)\n",
    "\n",
    "def getLeftElementsOfClasses(ancestors : List[Any], dag : nx.DiGraph, unrClasses : List[EquivalenceClass]):\n",
    "    leftElements = []\n",
    "    unrelatedTrees = 0\n",
    "\n",
    "    for unrClass in unrClasses: #These trees will always be available to use, because they are not related to any ancestor. They can go before the root of the ancestors even.\n",
    "            if isRoot(unrClass.classParent(), dag):\n",
    "                leftElements.append(unrClass.num_nodes_before())\n",
    "                unrelatedTrees += 1\n",
    "\n",
    "    for ancestor in ancestors:\n",
    "        ancestorChildren = list(dag.successors(ancestor))\n",
    "        for unrClass in unrClasses:\n",
    "            if unrClass.classParent() in ancestorChildren:\n",
    "                leftElements.append(unrClass.num_nodes_before())\n",
    "    return leftElements, unrelatedTrees\n",
    "\n",
    "# The idea would be that it has the left elements of each unrelated class, ordered by the ascendant node that is their parent. \n",
    "\n",
    "def getPossibleCombinations(leftElementsOfClasses: List[int], elementsToSelect: int) -> List[List[int]]:\n",
    "    def backtrack(index, current_combination, current_sum, maximumAmount):\n",
    "        # If the current sum equals the required elementsToSelect, add the combination to the result\n",
    "        if current_sum == elementsToSelect:\n",
    "            result.append(list(current_combination))\n",
    "            return\n",
    "        \n",
    "        if current_sum > elementsToSelect or index == len(leftElementsOfClasses) or current_sum + maximumAmount < elementsToSelect:\n",
    "            return\n",
    "        \n",
    "        for value in range(leftElementsOfClasses[index] + 1):\n",
    "            current_combination.append(value)\n",
    "            backtrack(index + 1, current_combination, current_sum + value, maximumAmount - leftElementsOfClasses[index])\n",
    "            current_combination.pop() \n",
    "\n",
    "    result = []\n",
    "    backtrack(0, [], 0, sum(leftElementsOfClasses))\n",
    "    return result\n",
    "\n",
    "# TODO: Add more pruning techniques. \n",
    "\n",
    "def numberOfUnrelatedSubtrees(node, dag : nx.DiGraph, classification : Dict[Any, NodeState]) -> int:\n",
    "    return len([child for child in dag.successors(node) if classification[child] == NodeState.UNRELATED])\n",
    "\n",
    "\n",
    "def removePutElements(putElements, leftElementsOfClasses : List[int]):\n",
    "    for i, put in enumerate(putElements):\n",
    "        leftElementsOfClasses[i] -= put\n",
    "\n",
    "def addPutElements(putElements, leftElementsOfClasses : List[int]):\n",
    "    for i, put in enumerate(putElements):\n",
    "        leftElementsOfClasses[i] += put\n",
    "\n",
    "memoHits = 0\n",
    "def possibleLeftOrders(actualPosition : int, leftElementsOfClasses : List[int], ancestorIndex : int, classesToUse : int , ancestors : List[Any], dag : nx.DiGraph, classification : Dict[Any, NodeState], memo: Dict[Tuple[int, Tuple[int], int, int], int]) -> int:\n",
    "    global memoHits\n",
    "    state = (actualPosition, tuple(leftElementsOfClasses), ancestorIndex, classesToUse)\n",
    "\n",
    "    if state in memo:\n",
    "        memoHits += 1\n",
    "        return memo[state]\n",
    "\n",
    "    if (sum(leftElementsOfClasses) == 0): #There are no more elements to select\n",
    "        return 1\n",
    "    \n",
    "    totalOrders = 0\n",
    "    #I just need to select all of the elements of the classes.\n",
    "    if (ancestorIndex == len(ancestors)): #I have already selected all the ancestors\n",
    "        \n",
    "        for comb in getPossibleCombinations(leftElementsOfClasses, sum(leftElementsOfClasses)):\n",
    "            totalOrders += multinomial_coefficient(comb)\n",
    "        \n",
    "        memo[state] = totalOrders\n",
    "        return totalOrders\n",
    "\n",
    "    actualAncestor = ancestors[ancestorIndex]\n",
    "    usableElements = leftElementsOfClasses[:classesToUse]\n",
    "\n",
    "    for ancestorPosition in range(actualPosition, actualPosition + sum(usableElements) + 1):\n",
    "        positionsToFill = ancestorPosition - actualPosition\n",
    "        for comb in getPossibleCombinations(usableElements, positionsToFill):\n",
    "            removePutElements(comb, leftElementsOfClasses)\n",
    "            newClassesToUse = classesToUse +  numberOfUnrelatedSubtrees(actualAncestor, dag, classification)\n",
    "            totalOrders += multinomial_coefficient(comb) * possibleLeftOrders(ancestorPosition+1, leftElementsOfClasses, ancestorIndex + 1, newClassesToUse, ancestors, dag, classification, memo)\n",
    "            addPutElements(comb, leftElementsOfClasses)\n",
    "    \n",
    "    memo[state] = totalOrders\n",
    "    return totalOrders\n",
    "\n",
    "# TODO: Make some of the variables global, so that I don't need to pass them as arguments\n",
    "\n",
    "#TODO : Improve the memoization data structure. Look if there is a structure that is useful for this kind of problem. Â¿Maybe use lru_cache or other structure?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Equivalence Classes manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unionOf(equivalence_classes : List[EquivalenceClass], addLeftToposOrder : bool = True) -> EquivalenceClass:\n",
    "    n = len(equivalence_classes)\n",
    "    positions = []\n",
    "    nodes_before = [0]*n\n",
    "    nodes_after = [0]*n\n",
    "    left_topos = [0]*n\n",
    "    right_topos = [0]*n\n",
    "    for i,eq_class in enumerate(equivalence_classes):\n",
    "        nodes_before[i] = eq_class.num_nodes_before()\n",
    "        nodes_after[i] = eq_class.num_nodes_after()\n",
    "        left_topos[i] = eq_class.left_topo\n",
    "        right_topos[i] = eq_class.right_topo\n",
    "        positions = positions + eq_class.allNodes()\n",
    "\n",
    "    left_size = math.prod(left_topos)\n",
    "    if addLeftToposOrder:\n",
    "        left_size *= multinomial_coefficient(nodes_before)  \n",
    "        \n",
    "    right_size = multinomial_coefficient(nodes_after) * math.prod(right_topos)\n",
    "    return EquivalenceClass(positions, left_size, right_size)\n",
    "\n",
    "# TODO: Make some of the variables global, so that I don't need to pass them as arguments\n",
    "\n",
    "def lastUnionOf(unr_classes : List[List[EquivalenceClass]], ancestors : List[Any], descendants : List[Any], descendantsTopoSorts : int, dag : nx.DiGraph, classification : Dict[Any, NodeState]) -> List[EquivalenceClass]:\n",
    "    classes_combinations = list(itertools.product(*unr_classes)) #Generate al the possible combinations for each eqClass of each child with the eqClass of the other children. \n",
    "    \n",
    "    descendants_position = [NodePosition(des, True) for des in descendants]\n",
    "    descendants_eqClass = EquivalenceClass(descendants_position,1, descendantsTopoSorts) \n",
    "    classes = []\n",
    "    # All the descendants appear after the feature node, because all of them appear before it then it has 1 rigth_topo (the empty one). \n",
    "    if (len(ancestors) == 0):\n",
    "        classes = list(map(lambda mix : unionOf(list(mix)), classes_combinations))\n",
    "        \n",
    "        if len(descendants) != 0:\n",
    "            classes = [unionOf([descendants_eqClass, mix]) for mix in classes]\n",
    "\n",
    "    else:\n",
    "        memorization = {}\n",
    "        for unr_class in classes_combinations:\n",
    "            leftElements, unrelatedTrees = getLeftElementsOfClasses(ancestors, dag, unr_class)\n",
    "            classesToUse = unrelatedTrees\n",
    "            ascendantsCombinationsWithUnrelated = possibleLeftOrders(0, leftElements, 0, classesToUse , list(ancestors), dag, classification, memorization)\n",
    "\n",
    "            eqClass = unionOf(unr_class, False)\n",
    "\n",
    "            eqClass.addAncestors(ancestors)\n",
    "            eqClass.addLeftTopo(ascendantsCombinationsWithUnrelated)\n",
    "\n",
    "            if (len(descendants) != 0):\n",
    "                eqClass = unionOf([eqClass, descendants_eqClass])\n",
    "                \n",
    "            classes.append(eqClass)\n",
    "    \n",
    "    return classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topological sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns a hash that is the binary number which has 0 or 1 in the i-th position if the i-th unrelated node is before or after x_i\n",
    "\n",
    "class TopoSortHasher:\n",
    "    def __init__(self, nodes_classification: Dict[Any, NodeState]):\n",
    "        self._unrelated_nodes_ids = self._get_unrelated_nodes(nodes_classification)\n",
    "\n",
    "    def _get_unrelated_nodes(self, nodes_classification: Dict[Any, NodeState]):\n",
    "        unrelated_nodes = list(filter(lambda node: nodes_classification[node] == NodeState.UNRELATED, nodes_classification.keys()))\n",
    "        self._unrelated_nodes_ids = {node: i for i, node in enumerate(unrelated_nodes)}\n",
    "        return self._unrelated_nodes_ids\n",
    "\n",
    "    def hashTopoSort(self, topoSort: List[Any], x_i: Any) -> int:\n",
    "        unrelated_nodes = self._unrelated_nodes_ids\n",
    "        hash_val = 0\n",
    "        for node in topoSort:\n",
    "            if node == x_i:\n",
    "                break\n",
    "            if node in unrelated_nodes:\n",
    "                hash_val += 2 ** unrelated_nodes[node]\n",
    "        return hash_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the size of the tree and the number of topological sorts\n",
    "\n",
    "def sizeAndNumberOfTopoSorts(node, dag : nx.DiGraph):\n",
    "    if isLeaf(node, dag):\n",
    "        return 1,1\n",
    "    \n",
    "    childrenSubtreeSizes = []\n",
    "    children_topoSorts = []\n",
    "\n",
    "    \n",
    "    for child in dag.successors(node):\n",
    "        child_size, child_topos =  sizeAndNumberOfTopoSorts(child,dag)\n",
    "        children_topoSorts.append(child_topos)\n",
    "        childrenSubtreeSizes.append(child_size)\n",
    "        \n",
    "\n",
    "    topos = multinomial_coefficient(childrenSubtreeSizes) * math.prod(children_topoSorts)\n",
    "    return sum(childrenSubtreeSizes)+1, topos\n",
    "\n",
    "    \n",
    "def topoSortsFrom(node, dag : nx.DiGraph):\n",
    "   _, topos = sizeAndNumberOfTopoSorts(node, dag)\n",
    "   return topos\n",
    "\n",
    "#TODO : Add dynamic programming so that each node knows its result.\n",
    "\n",
    "def allTopoSorts(dag : nx.DiGraph):\n",
    "    #Add a root node to the graph that is connected to all the roots of the graph.\n",
    "    roots = [node for node in dag.nodes() if isRoot(node, dag)]\n",
    "\n",
    "    dag.add_node('Root')\n",
    "\n",
    "    for root in roots:\n",
    "        dag.add_edge('Root', root)\n",
    "        \n",
    "    res = topoSortsFrom('Root', dag)\n",
    "    dag.remove_node('Root')\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_topological_sort(G, ordering):\n",
    "    position = {node: i for i, node in enumerate(ordering)}\n",
    "    \n",
    "    # Check that for each edge (u, v) in the graph, u appears before v in the ordering\n",
    "    for u, v in G.edges():\n",
    "        if position[u] >= position[v]:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Equivalence Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numberOfEquivalenceClasses(dag : nx.DiGraph, feature_nodes : Any):\n",
    "    nodes_classification = {}\n",
    "    unrelated_roots = classifyNodes(dag, feature_nodes, nodes_classification)\n",
    "    if unrelated_roots == []:\n",
    "        return 1\n",
    "\n",
    "    dag.add_node('Root')\n",
    "    for root in unrelated_roots:\n",
    "        dag.add_edge('Root', root)\n",
    "    res = numOfClasses(dag, 'Root')\n",
    "    dag.remove_node('Root')\n",
    "    return res\n",
    "    \n",
    "\n",
    "def numOfClasses(dag : nx.DiGraph, node):\n",
    "    if isLeaf(node, dag):\n",
    "        return 2\n",
    "    \n",
    "    childResult = list(map(lambda child : numOfClasses(dag, child), dag.successors(node)))\n",
    "\n",
    "    return 1 + math.prod(childResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Equivalence Classes Formulas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recursive Equivalence Class formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unrelatedEquivalenceClassesSizes(node, dag : nx.DiGraph) -> List[EquivalenceClass]:\n",
    "    if isLeaf(node, dag):\n",
    "        classes = []\n",
    "        for x in [False, True]:\n",
    "           classes.append(EquivalenceClass([NodePosition(node, x)]))\n",
    "        return classes\n",
    "    \n",
    "    children_classes = list(map(lambda child : unrelatedEquivalenceClassesSizes(child,dag), dag.successors(node)))\n",
    "\n",
    "    classes_combinations = list(itertools.product(*children_classes)) #Generate al the possible combinations for each eqClass of each child with the eqClass of the other children. \n",
    "    \n",
    "    # All the equivalence classes will have this node in the left part. \n",
    "\n",
    "    classes = list(map(lambda mix : uniteChildrenAndAddParent(node, list(mix)), classes_combinations))\n",
    "\n",
    "    allRight = unionOf(list(classes_combinations[len(classes_combinations)-1]))\n",
    "    if allRight.num_nodes_before() == 0:\n",
    "        allRight.addParentToRigth(node)\n",
    "        classes.append(allRight)\n",
    "        # If the parent is to the right, then all of the children should be after the feature node\n",
    "\n",
    "        # TODO: I think that this kind of union (all in the right part) will always be the last element of classes_combinations, so we can just take the \n",
    "        # first element of classes_combination to do this, I need to review this.\n",
    "    return classes\n",
    "\n",
    "#TODO : Add dynamic programming so that it stores the result of the run for each node, or it stores some results so that it can reconstruct the solution.\n",
    "\n",
    "def uniteChildrenAndAddParent(node, equivalence_classes : List[EquivalenceClass]) -> EquivalenceClass:\n",
    "        union = unionOf(equivalence_classes)\n",
    "        union.addParent(node)\n",
    "\n",
    "        return union\n",
    "\n",
    "#They need to be ordered in the same way that the nodes are ordered in the graph, because in the possibleLeftOrders we are putting them assuming they have the same order as in the graph\n",
    "\n",
    "def orderedNodes(dag : nx.DiGraph, nodesToOrder : List[Any]) -> List[Any]:\n",
    "    topo_sorted_nodes = list(nx.topological_sort(dag))\n",
    "    ordered_ancestors = [n for n in topo_sorted_nodes if n in nodesToOrder]\n",
    "    \n",
    "    return ordered_ancestors\n",
    "\n",
    "\n",
    "def recursiveEquivalenceClassesSizes(dag : nx.DiGraph, unr_roots : List[Any], hasher : TopoSortHasher, feature_node, nodes_classification : Dict[Any, NodeState]) -> List[EquivalenceClass]:\n",
    "    unr_classes = list(map(lambda child : unrelatedEquivalenceClassesSizes(child,dag), unr_roots))\n",
    "    ancestors = orderedNodes(dag, nx.ancestors(dag, feature_node))\n",
    "    descendants = orderedNodes(dag, nx.descendants(dag, feature_node))\n",
    "\n",
    "    descendantsTopoSorts = topoSortsFrom(feature_node, dag)\n",
    "    recursiveClassesSizes = lastUnionOf(unr_classes, ancestors, descendants, descendantsTopoSorts, dag, nodes_classification)\n",
    "\n",
    "    recursiveClassesSizes = hashEquivClasses(recursiveClassesSizes, hasher, feature_node, dag)\n",
    "    return recursiveClassesSizes\n",
    "\n",
    "\n",
    "\n",
    "def hashEquivClasses(equivClasses : List[EquivalenceClass], hasher : TopoSortHasher , feature_node, dag : nx.DiGraph):\n",
    "    hashedClasses = {}\n",
    "    for eqClass in equivClasses:\n",
    "        topoSortForClass = eqClass.topologicalSort(feature_node)\n",
    "        if not is_topological_sort(dag, topoSortForClass):\n",
    "            raise AssertionError(f\"The topological sort {topoSortForClass} is not a valid topological sort for the graph, for the feature node {feature_node}\")\n",
    "        hash = hasher.hashTopoSort(topoSortForClass, feature_node)\n",
    "        hashedClasses[hash] = [topoSortForClass,  eqClass.classSize()]\n",
    "    \n",
    "    return hashedClasses\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Equivalence Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveEquivalenceClassesSizes(all_topo_sorts : List[List[Any]], feature_node : Any, hasher : TopoSortHasher):\n",
    "      \n",
    "   result = {} \n",
    "   for topoSort in all_topo_sorts:\n",
    "      hash = hasher.hashTopoSort(topoSort, feature_node)\n",
    "      actual_value = result.get(hash, [topoSort, 0])\n",
    "      result[hash] = [actual_value[0], actual_value[1] + 1] \n",
    "      # It has a representative of each class and the number of topological orders that are in that class.\n",
    "\n",
    "   return result\n",
    "\n",
    "#TODO: Here I don't need the topological orders with the descendants of feature_node, I can remove them and then multiply the number of topological orders of each class. \n",
    "# To do this I just need to calculate the \"merging\" of this possible topological orders as I do in the recursive approach. So when I calculate all_topo_sorts I\n",
    "# can do it with only the unrelated nodes and the ascendants, removing the descendants. But to do do this I need to recalculate all_topo_sorts for each feature node.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertEquivalenceClassesForNode(dag: nx.DiGraph, feature_node, all_topo_sorts: List[List[Any]], timing_dict: Dict[str, Dict[str, float]]):\n",
    "    \n",
    "    nodes_classification = {}\n",
    "    unr_roots = classifyNodes(dag, feature_node, nodes_classification)\n",
    "    hasher = TopoSortHasher(nodes_classification)\n",
    "\n",
    "    # Naive approach\n",
    "    start_time = time.time()\n",
    "    naiveClassesSizes = naiveEquivalenceClassesSizes(all_topo_sorts, feature_node, hasher)\n",
    "    end_time = time.time()\n",
    "    timing_dict[feature_node]['Naive Formula'] = end_time - start_time\n",
    "\n",
    "    # Recursive approach\n",
    "    start_time = time.time()\n",
    "    recursiveClassesSizes = recursiveEquivalenceClassesSizes(dag, unr_roots, hasher, feature_node, nodes_classification)\n",
    "    end_time = time.time()\n",
    "    timing_dict[feature_node]['Recursive Formula'] = end_time - start_time\n",
    "\n",
    "    timing_dict[feature_node]['Number of equivalence classes'] = len(naiveClassesSizes.keys())\n",
    "    \n",
    "    # Assert that each equivalence class has the same number of elements.\n",
    "\n",
    "    naiveEqClasses = len(naiveClassesSizes.keys())\n",
    "    recursiveEqClasses = len(recursiveClassesSizes.keys())\n",
    "    if naiveEqClasses != recursiveEqClasses and numberOfEquivalenceClasses(dag, feature_node) != naiveEqClasses:\n",
    "        raise AssertionError(f\"The number of equivalence classes is different. \\n Naive Approach: {naiveEqClasses}, Recursive Approach: {recursiveEqClasses} \\n Feature Node: {feature_node}\")\n",
    "\n",
    "    for eqClassHash in naiveClassesSizes.keys():\n",
    "        clSize1 = naiveClassesSizes[eqClassHash][1]\n",
    "        clTopo1 = naiveClassesSizes[eqClassHash][0]\n",
    "        try: \n",
    "            clSize2 = recursiveClassesSizes[eqClassHash][1]\n",
    "            clTopo2 = recursiveClassesSizes[eqClassHash][0]\n",
    "        except KeyError:\n",
    "            raise AssertionError(f\"The equivalence class {eqClassHash} is not present in the recursive approach. \\n Naive Approach: Topo {clTopo1}, Size {clSize1} \\n Feature Node: {feature_node}\")\n",
    "        if (clSize1 != clSize2):\n",
    "            raise AssertionError(f\"The sizes of the equivalence classes are not equal. \\n Naive Approach: Topo {clTopo1}, Size {clSize1} \\n Recursive Approach: Topo {clTopo2}, Size {clSize2} \\n Feature Node: {feature_node}\")\n",
    "\n",
    "#TODO: Find a better algorithm than all_topological_sorts, it takes too much time. In the paper they mention a dynamic programming approach, maybe implement that. This takes too much time.\n",
    "\n",
    "def assertEquivClassesForDag(dag: nx.DiGraph, nodesToEvaluate = None, allSorts = None) -> Dict[str, float]:\n",
    "    timing_dict = {}\n",
    "    \n",
    "    # Measure time for all topological sorts\n",
    "    start_time = time.time()\n",
    "    all_topo_sorts = allSorts if allSorts != None else list(nx.all_topological_sorts(dag))\n",
    "    assert len(all_topo_sorts) == allTopoSorts(dag)\n",
    "    end_time = time.time()\n",
    "    timing_dict['Time Of Topological Sorts'] = end_time - start_time\n",
    "    timing_dict['Number of Topological Sorts'] = len(all_topo_sorts)\n",
    "    \n",
    "    nodesToEvaluate = nodesToEvaluate if nodesToEvaluate != None else list(dag.nodes)\n",
    "    for node in nodesToEvaluate:\n",
    "            timing_dict[node] = {}\n",
    "            assertEquivalenceClassesForNode(dag, node, all_topo_sorts, timing_dict)\n",
    "    \n",
    "    return timing_dict\n",
    "\n",
    "def drawGraph(dag : nx.DiGraph):\n",
    "    pos = nx.spring_layout(dag)\n",
    "    nx.draw(dag, pos, with_labels=True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Empty graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "numNodes = 5\n",
    "\n",
    "emptyGraph = nx.DiGraph()\n",
    "nodes = [i for i in range(numNodes)]\n",
    "emptyGraph.add_nodes_from(nodes)\n",
    "\n",
    "#drawGraph(emptyGraph)\n",
    "res = assertEquivClassesForDag(emptyGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naiveBayesOf(numNodes : int):\n",
    "    naive_bayes = nx.DiGraph()\n",
    "    nodes = [i for i in range(numNodes)]\n",
    "    naive_bayes.add_nodes_from(nodes)\n",
    "    root = list(naive_bayes.nodes)[0]\n",
    "    for node in nodes:\n",
    "        if node != root:\n",
    "            naive_bayes.add_edge(root, node)\n",
    "    return naive_bayes\n",
    "\n",
    "numNodes = 7\n",
    "naiveBayes = naiveBayesOf(numNodes)\n",
    "\n",
    "#drawGraph(naiveBayes)\n",
    "\n",
    "res = assertEquivClassesForDag(naiveBayes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes with Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "numNodes = 3\n",
    "lengthOfPath = 10\n",
    "\n",
    "naiveBayesWithPath = naiveBayesOf(numNodes)\n",
    "\n",
    "for path_node in range(numNodes,numNodes+lengthOfPath):\n",
    "    naiveBayesWithPath.add_node(path_node)\n",
    "    naiveBayesWithPath.add_edge(path_node-1, path_node)\n",
    "\n",
    "#drawGraph(naiveBayesWithPath)\n",
    "res = assertEquivClassesForDag(naiveBayesWithPath, [0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplePaths(numPaths, nodesPerPath) -> nx.DiGraph:\n",
    "    multiplePaths = nx.DiGraph()\n",
    "    multiplePaths.add_node(0)\n",
    "\n",
    "    nodeCounter = 0\n",
    "    for path in range(1,numPaths+1):\n",
    "        for node in range(1,nodesPerPath+1):\n",
    "            if node != 1:\n",
    "                multiplePaths.add_edge(nodeCounter-1, nodeCounter)\n",
    "            nodeCounter += 1\n",
    "    \n",
    "    return multiplePaths\n",
    "\n",
    "\n",
    "numberOfPaths = 3\n",
    "pathLenght = 3\n",
    "\n",
    "multiplePathGraph = multiplePaths(numberOfPaths, pathLenght)\n",
    "#drawGraph(multiplePathGraph)\n",
    "res = assertEquivClassesForDag(multiplePathGraph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Balanced Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balancedTree(height: int, branchingFactor: int = 2) -> nx.DiGraph:\n",
    "\n",
    "    balanced_tree = nx.DiGraph()\n",
    "    current_level_nodes = [0]\n",
    "    balanced_tree.add_node(0)\n",
    "    node_counter = 1\n",
    "    \n",
    "    for _ in range(1, height):\n",
    "        next_level_nodes = []\n",
    "        for parent in current_level_nodes:\n",
    "            for _ in range(branchingFactor):\n",
    "                balanced_tree.add_node(node_counter)\n",
    "                balanced_tree.add_edge(parent, node_counter)\n",
    "                next_level_nodes.append(node_counter)\n",
    "                node_counter += 1\n",
    "        current_level_nodes = next_level_nodes\n",
    "    \n",
    "    return balanced_tree\n",
    "\n",
    "numLevels = 2\n",
    "branchingFactor = 3\n",
    "balanced_tree = balancedTree(numLevels, branchingFactor)\n",
    "\n",
    "#drawGraph(balanced_tree)\n",
    "\n",
    "res = assertEquivClassesForDag(balanced_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing of All Topo Sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_allTopos(graph):\n",
    "    all_topos = allTopoSorts(graph)\n",
    "    all_topo_sorts = list(nx.all_topological_sorts(graph))\n",
    "    assert all_topos == len(all_topo_sorts), \"allTopos and all_topological_sorts have different lengths\"\n",
    "\n",
    " \n",
    "# Test allTopos function for different graphs\n",
    "#test_allTopos(emptyGraph)\n",
    "#test_allTopos(naiveBayes)\n",
    "#test_allTopos(naiveBayesWithPath)\n",
    "#test_allTopos(multiplePathGraph)\n",
    "#test_allTopos(balanced_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def disablePrint():\n",
    "    original_stdout = sys.stdout\n",
    "    sys.stdout = open(os.devnull, 'w')\n",
    "    return original_stdout\n",
    "\n",
    "def enablePrint():\n",
    "    sys.stdout.close()\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "def measure_graph_data(dag: nx.DiGraph, nodesToEvaluate : List[Any]) -> Dict[str, Any]:\n",
    "\n",
    "    times_per_node = []\n",
    "    equiv_classes_per_node = []\n",
    "\n",
    "    graph_data = timeRecursiveFunctionFor(dag, nodesToEvaluate)\n",
    "\n",
    "    for node in nodesToEvaluate:\n",
    "        node_data = graph_data[node]\n",
    "        times_per_node.append(node_data['Total Time'])\n",
    "        equiv_classes_per_node.append(numberOfEquivalenceClasses(dag, node))\n",
    "\n",
    "\n",
    "    def obtainMaxMinAvg(data):\n",
    "        maxValue = max(data)\n",
    "        maxValue = str(maxValue) + f', Index of node: {data.index(maxValue)}'\n",
    "        minValue = min(data)\n",
    "        minValue = str(minValue) + f', Index of node: {data.index(minValue)}'\n",
    "        average = sum(data) / len(data)\n",
    "        return maxValue, minValue, average\n",
    "   \n",
    "    longest_time, shortest_time, average_time = obtainMaxMinAvg(times_per_node)\n",
    "    biggest_equiv_classes, smallest_equiv_classes, average_equiv_classes = obtainMaxMinAvg(equiv_classes_per_node)\n",
    "\n",
    "    return {\n",
    "        \"allTopoSortsNumber\": allTopoSorts(dag),\n",
    "        \"recursiveLongestTime\": longest_time,\n",
    "        \"recursiveShortestTime\": shortest_time,\n",
    "        \"recursiveAverageTime\": average_time,\n",
    "        \"biggestEquivClasses\": biggest_equiv_classes,\n",
    "        \"smallestEquivClasses\": smallest_equiv_classes,\n",
    "        \"averageEquivClasses\": average_equiv_classes,\n",
    "    }\n",
    "\n",
    "def timeOfAllTopologicalSorts(dag, printTime = 500000, maxTopoSorts = 10000000):\n",
    "    allTopoSorts = []\n",
    "    timing_dict = {}\n",
    "    start_time = time.time()\n",
    "    for topoSort in nx.all_topological_sorts(dag):\n",
    "        allTopoSorts.append(topoSort)\n",
    "        if (len(allTopoSorts) % printTime == 0):\n",
    "            timing_dict[len(allTopoSorts)]= time.time() - start_time\n",
    "            print(f'Number of topological sorts: {len(allTopoSorts)}, time: {timing_dict[len(allTopoSorts)]}')\n",
    "        if (len(allTopoSorts) == maxTopoSorts):\n",
    "            break\n",
    "    return timing_dict, allTopoSorts\n",
    "\n",
    "def timeRecursiveFunctionParts(dag : nx.DiGraph, unr_roots : List[Any], hasher : TopoSortHasher, feature_node, nodes_classification : Dict[Any, NodeState]) -> List[EquivalenceClass]:\n",
    "    run_data = {}\n",
    "\n",
    "    start_time = time.time()\n",
    "    unr_classes = list(map(lambda child : unrelatedEquivalenceClassesSizes(child,dag), unr_roots))\n",
    "    end_time = time.time()\n",
    "    run_data['Unrelated Classes Calculation'] = end_time - start_time\n",
    "\n",
    "    ancestors = list(nx.ancestors(dag, feature_node))\n",
    "    descendants = list(nx.descendants(dag, feature_node))\n",
    "\n",
    "    descendantsTopoSorts = topoSortsFrom(feature_node, dag)\n",
    "    start_time = time.time()\n",
    "    recursiveClassesSizes = lastUnionOf(unr_classes, ancestors, descendants, descendantsTopoSorts, dag, nodes_classification)\n",
    "    assert (sum(map(lambda eqClass : eqClass.classSize(),recursiveClassesSizes)) == allTopoSorts(dag)), \"The number of topological sorts is not the same as the sum of the topological sorts of the equivalence classes\"\n",
    "    end_time = time.time()\n",
    "    run_data['Last Union Calculation'] = end_time - start_time\n",
    "\n",
    "    return run_data\n",
    "\n",
    "def timeRecursiveFunctionFor(dag, nodesToEvaluate):\n",
    "    global memoHits\n",
    "    timing_dict = {}\n",
    "    for feature_node in nodesToEvaluate:\n",
    "        print(f'Runing for node {feature_node} which has {numberOfEquivalenceClasses(dag, feature_node)} equivalence classes')\n",
    "        memoHits = 0\n",
    "        timing_dict[feature_node] = {}\n",
    "        nodes_classification = {}\n",
    "        unr_roots = classifyNodes(dag, feature_node, nodes_classification)\n",
    "        hasher = TopoSortHasher(nodes_classification)\n",
    "        # Recursive approach\n",
    "        start_time = time.time()\n",
    "        recursiveFunctionResult = timeRecursiveFunctionParts(dag, unr_roots, hasher, feature_node, nodes_classification)\n",
    "        end_time = time.time()\n",
    "        timing_dict[feature_node]['Recursive Formula'] = recursiveFunctionResult\n",
    "        timing_dict[feature_node]['Total Time'] = end_time - start_time\n",
    "        timing_dict[feature_node]['Memoization Hits'] = memoHits\n",
    "    \n",
    "        print(f'Node {feature_node} took {timing_dict[feature_node][\"Total Time\"]} seconds to run')\n",
    "    return timing_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple paths with different lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplePaths(numPaths, nodesPerPath) -> nx.DiGraph:\n",
    "    multiplePaths = nx.DiGraph()\n",
    "    multiplePaths.add_node(0)\n",
    "\n",
    "    nodeCounter = 0\n",
    "    for _ in range(1,numPaths+1):\n",
    "        multiplePaths.add_node(nodeCounter)\n",
    "        for node in range(1,nodesPerPath+1):\n",
    "            if node != 1:\n",
    "                multiplePaths.add_edge(nodeCounter-1, nodeCounter)\n",
    "            nodeCounter += 1\n",
    "    \n",
    "    return multiplePaths\n",
    "\n",
    "def timeMultiplePathsGraphs(numPaths, pathLength, startFrom = 1):\n",
    "    graphsResults = {}\n",
    "    for i in range(startFrom,numPaths+1):\n",
    "        for j in range(startFrom,pathLength+1):\n",
    "            graphToEvaluate = multiplePaths(i, j)\n",
    "            #drawGraph(graphToEvaluate)\n",
    "            nodesToEvaluate = list(range(0, j))\n",
    "            #print(f'{i} Paths, {j} Length' + str(nodesToEvaluate))\n",
    "            graphsResults[f'{i} Paths, {j} Length'] = measure_graph_data(graphToEvaluate, nodesToEvaluate)\n",
    "\n",
    "    return graphsResults\n",
    "    \n",
    "\n",
    "numberOfPaths = 3\n",
    "pathLenght = 2\n",
    "graph = multiplePaths(numberOfPaths, pathLenght)\n",
    "allTopos = allTopoSorts(graph)\n",
    "\n",
    "res = timeRecursiveFunctionFor(graph, list(range(0, pathLenght)))\n",
    "#res = timeMultiplePathsGraphs(numberOfPaths, pathLenght)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of topological sorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numberOfPaths = 4\n",
    "pathLenght = 5\n",
    "graph = multiplePaths(numberOfPaths, pathLenght)\n",
    "\n",
    "#res = timeOfAllTopologicalSorts(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Time depending on Equivalence Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeMultipleBalancedTrees(numLevels, branchingFactor = 2, startLevels = 1, starBranching = 2):\n",
    "    graphsResults = {}\n",
    "    for i in range(startLevels,numLevels+1):\n",
    "        for j in range(starBranching,branchingFactor+1):\n",
    "            graphToEvaluate = balancedTree(i, j)\n",
    "            #drawGraph(graphToEvaluate)\n",
    "            leafNode = [node for node in graphToEvaluate.nodes if isLeaf(node, graphToEvaluate)][0]\n",
    "            pathToLeaf = orderedNodes(graphToEvaluate, nx.ancestors(graphToEvaluate, leafNode)) + [leafNode]\n",
    "            #print(f'{i} Levels, {j} Branching' + str(pathToLeaf))\n",
    "            graphsResults[f'{i} Levels, {j} Branching'] = measure_graph_data(graphToEvaluate, pathToLeaf)\n",
    "            #print()\n",
    "\n",
    "    return graphsResults\n",
    "\n",
    "numLevels = 4\n",
    "branchingFactor = 2\n",
    "\n",
    "res = timeMultipleBalancedTrees(numLevels, branchingFactor, numLevels, branchingFactor)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
