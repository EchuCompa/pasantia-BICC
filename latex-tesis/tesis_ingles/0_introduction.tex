Let $X$ be a finite set of features. An entity $e$ over $X$ is a mapping $e: X \to \{0,1\}$\footnote{We could consider a non-binary but finite codomain $\domain_x$ for each $x \in X$ and adapt all definitions}, and we denote by $\entities(X)$ the set of all $2^n$ possible entities. A binary\footnote{Here we could also consider models with a finite codomain} classifier $M$ over entities $X$ is a mapping from $\entities(x)$ to $\{0,1\}$.

A \textit{feature attribution score} for model $M$ and entity $e$ is a mapping $\phi : X \to \R$ such that $\phi(x)$ indicates the \textit{score} or \textit{relevance} of feature $x$ with respect to the prediction $M(e)$. One of the most prominent feature attribution scores is the \SHAPscore{} \cite{lundberg2017unified}, which is based on the Shapley values \cite{shapley1953value} from cooperative game theory. In that context, the Shapley values represent the unique distributional schema of the surplus obtained by a coalition of players satisfying some desirable properties.

More formally, let $\players$ be a finite a set of players, and define a \textit{characteristic function} for $\players$ as a function $\charactheristicFunction : \mathcal{P}(\players) \to \R$ assigning a surplus to each possible \textit{coalition} of the players (i.e. subset of the players). The Shapley values $\{\phi_i\}_{i \in \players}$ are the unique functions taking as input characteristic functions and outputting real values satisfying

\begin{itemize}
    \item \textbf{Efficiency}: all the surplus is distributed.

    \begin{align*}
        \sum_{i \in \players} \phi_i(\charactheristicFunction) = \charactheristicFunction(\players)
    \end{align*}

    \item \textbf{Symmetry}: any pair of players $i,j \in \players$ that contribute the same receive the same reward.

    \begin{align*}
        \forall i,j \in \players : \left( \bigwedge_{S \subseteq \players \setminus \{i,j\}} \charactheristicFunction(S \cup \{i\}) = \charactheristicFunction(S \cup \{j\}) \right) \implies \phi_i(\charactheristicFunction) = \phi_j(\charactheristicFunction) 
    \end{align*}

    \item \textbf{Linearity}: if two games are combined, then the solution to that new game is the sum of the solutions for the original ones. If a characteristic function is multiplied by a scalar, then the solution is also multiplied by it.

    \begin{align*}
        \forall a \in \R : 
        \phi_i(a \charactheristicFunction_1 + \charactheristicFunction_2) =  a \phi_i(\charactheristicFunction_1) + \phi_i(\charactheristicFunction_2)
    \end{align*}

    \item \textbf{Null player}: if a player does not contribute in any coalition, then it gets no reward.

    \begin{align*}
        \forall i \in \players : \left( \bigwedge_{S \subseteq \players \setminus \{i\}} \charactheristicFunction(S) = \charactheristicFunction(S \cup \{i\}) \right) \implies \phi_i(\charactheristicFunction) = 0
    \end{align*}
    
\end{itemize}

Moreover, there is a simple closed form for these functions. Given a finite set $A$ let $perm(A)$ be the set of all its permutations, and given $\pi \in \perm(A)$ we denote as $\pi_{<a}$ the set $\{a' \in A : \pi(a') < \pi(a)\}$. Then

\begin{align}\label{eq:shapley_values_by_perm}
    \phi_i(\charactheristicFunction) = \frac{1}{|\players|!} \sum_{\pi \in \perm(\players)} \left[\charactheristicFunction(\pi_{<i} \cup {i}) - \charactheristicFunction(\pi_{<i})\right]
\end{align}

Intuitively, this function considers all possible orders in which the players arrive to the game, and leverages the contribution that $i$ provides on his arrival. It can be proven that

\begin{align*}
    \phi_i(\charactheristicFunction) = \sum_{S \subseteq \players \setminus \{i\}} c_{|S|}\left[\charactheristicFunction(S \cup {i}) - \charactheristicFunction(S)\right]
\end{align*}

where $c_m = \frac{m! |\players|-m-1!}{|\players|!}$.

The analogy with machine learning emerges by understanding the set of $n$ features $X$ as players, and the characteristic function $\charactheristicFunction$ as the average prediction when considering a subset of these features fixed. Given $M$ and $e$, we define the set of entities consistent with $e$ up to the subset of features $S \subseteq X$ as $\consistsWith(e, S) = \{e' \in \entities(X) : e'(s) = e(s) \text{ for } s \in S\}$. Then, the characteristic function is defined as

\begin{align*}
    \charFunML_{M,e,\Pr}(S) = E[M(e') | \consistsWith(e,S)] = \sum_{e' \in \consistsWith} Pr[e' | \consistsWith(e,S)] M(e')
\end{align*}

where we considered some probability space for the set $\entities(X)$ given by $\Pr$. For convenience, for a model $M$, entity $e$ and distribution $\Pr$ we will note the Shapley values as

\begin{align*}
    \Shap_{M,e,\Pr}(x_i) = \sum_{S \subseteq X \setminus \{x_i\}} c_{|S|} \left[ \charFunML_{M,e,\Pr}(S \cup \{x_i\}) - \charFunML_{M,e,\Pr}(S) \right]
\end{align*}

Note that the axioms that these values satisfy do not have a clear meaning in the context of AI because they depend on the definition of $\charFunML_{M,e,\Pr}$ \cite{fryer2021shapley}. Moreover, for some simple and robust notions of \textit{feature relevance} based on \textit{abductive explanations} \cite{marques2023logic} the Shapley values fail to assign score 0 to irrelevant features \cite{huang2023inadequacy}.


\section{Complexity of Shapley-based explanations}

\subsection{Known results for the Shapley values}

Computing these values in polynomial time on the model size is challenging: observe, for example, that the outer summation iterates through a set of exponential size on the number of features $n$. Nonetheless, for some specific families of models and distributions, it is possible to develop efficient algorithms.

The first result of these kind came from \cite{lundberg2020local}, where the authors provide a polynomial-time algorithm for computing the Shapley values for decision trees under the \textit{product} or \textit{fully-factorized distribution}. Such a distribution would arise naturally under the unrealistic assumption of \textit{feature independence}. In such a scenario, we would have, for each $x \in X$, a value $p_x$ indicating the probability that feature $x$ has value 1 in a random entity. Thus, it follows that

\begin{align*}
    \Pr[e' | \consistsWith(e, S)] = \prod_{\substack{x \in X \setminus S \\ e'(x) = 1}} p_x \prod_{\substack{x \in X \setminus S \\ e'(x) = 0}} (1-p_x) 
\end{align*}

These results were extended in \cite{arenas2021tractability}, where it was proven that it is also possible to compute the Shapley values for product distributions when the model is conditioned to be a \textit{deterministic} and \textit{decomposable} circuit. Moreover, they showed that removing any one of these conditions renders the problem \sharpPhard, and in a latter paper they also obtained non-approximability results \cite{arenas2023complexity}.

A more general result was proven simultaneously in \cite{van2022tractability}: it is possible to compute the Shapley values for a family of models $\mathcal{F}$ under the product distribution if and only if it is possible to compute the average prediction for that model given any set of probabilities $\{p_x\}_{x \in X}$ in polynomial time. Through this lemma they immediately deduce the feasibility of computing the Shapley values for linear regression models, decision trees, d-DNNF boolean functions and CNF circuits of bounded tree-width. Then they also proved the intractability of this problem for more expressive models such as logistic regression models, neural networks with sigmoid activation functions and general CNF boolean functions.

In \cite{lundberg2020local} it is claimed that it is possible to compute the Shapley values for decision trees under the \textit{empirical distribution}, which is the one given by the training data. More formally, given a multiset of samples $D \subseteq \entities(X)$ of size $m$ the empirical distribution induced by $D$ is defined as

\begin{align*}
    \Pr[e'] = \frac{D(e')}{m} 
\end{align*}

where $D(e')$ indicates the number of copies of $e'$ that $D$ contains. Observe that the probability of an unseen entity is 0.

The authors do not provide any proof supporting the correctness of the algorithm, and furthermore in \cite{van2022tractability} it is proven that for this kind of distribution the problem of computing the Shapley values is \sharpPhard{} even for extremely simple models and, in particular, for decision trees\footnote{More precisely, the claim of hardness holds for any family of models which contains functions that are dependent on only one of the input features}.

Lastly, in \cite{van2022tractability} it is also shown that the problem is \sharpPhard{} as well when considering the trivial model $f(x_1,\ldots,x_n) = x_1$ and a Naive Bayes Distribution. Since any reasonable family of models contains this kind of functions, the possibility of developing efficient algorithms to compute Shapley Values under Bayesian distributions seems narrow.

\santi{Agregar explicacion de que es una Naive Bayes Distribution.}

\subsection{Alternatives to the Shapley values}

\subsubsection{Asymmetric Shapley values}

The definition for the Shapley values from Equation~\ref{eq:shapley_values_by_perm} weights every possible permutation equally. In general, we could consider a weight function $w:\perm(\players) \to R$ and define

\begin{align}\label{eq:assymetric_shap_def}
   \phi_{i}^{assym}(\charactheristicFunction) = \sum_{\pi \in \perm(\players)} w(\pi) \left[ \charactheristicFunction(\pi_{<i} \cup {i}) - \charactheristicFunction(\pi_{<i}) \right] 
\end{align}

Assuming $\sum_{\pi \in \perm(\players)} w(\pi) = 1$, this is the most general expression for any function satisfying Efficiency, Linearity and Null Player \cite{frye2019asymmetric}. For any weight function different from the uniform one $\phi_i^{assym}$ does not satisfy Symmetry (and thus the name).

In \cite{frye2019asymmetric} they define the \textit{Assymetric Shapley Values} by considering the definition from Equation~\ref{eq:assymetric_shap_def}
and a weight function based on the causal graph of the feature space. More formally, it is assumed that we have access to a DAG (Directed Acyclic Graph) $G = (X, E)$ where the nodes of $G$ are the features $X$. The set $\topo(G)$ of topological orders of $G$ is a subset of $\perm(X)$, and we can define a weight function $w$ as

\begin{align*}
    w(\pi) = \begin{cases}
        \frac{1}{|\topo(G)|} & \pi \in \topo(G) \\
        0 & \text{otherwise}
    \end{cases}    
\end{align*}

\santi{Entiendo que $|\topo(G)|$ se puede calcular en polinomial, hay que revisarlo.}
\santi{Bueno, parece que no lo es, por lo menos en general \url{https://stackoverflow.com/questions/67619228/is-there-any-way-to-count-the-total-number-of-topological-sort-in-a-dag-without}. De todas formas podemos asumirlo dado o ignorarlo completamente. Si lo ignoramos ocurre que se pierde eficiencia, en principio. }

and the \textit{Assymeric Shapley values} as

\begin{align*}
    \assym_{M,e,\Pr}(x_i) = \sum_{\pi \in \topo(G)} [\charactheristicFunction_{M,e,\Pr}(\pi_{<i} \cup \{x_i\}) - \charactheristicFunction_{M,e,\Pr}(\pi_{<i})] 
\end{align*}

Intuitively, the Assymetric Shapley values filter out permutations that do not respect the causality defined by the DAG $G$.

This causal graph was introduced to model correlations between the variables at the level of the score itself, independently of the underlying distribution. But we can consider that instead of having a causal graph, we are provided with a Bayesian Network describing the distribution of the features space itself, which in particular contains a DAG we can employ as the causality graph.

A Bayesian Network for features $X$ is a tuple $\aBayesianNetwork = (X, E, \Pr)$ where $(X, E)$ is a DAG that has the features $X$ as nodes and $\Pr$ is a function that encodes, for each feature $X$, its conditional probability distribution $\Pr[X | \parents(X)]$. The topological semantics specify that each variable is conditionally independent of its non-descendants given its parents (and that's why the information from $\Pr$ is enough to reconstruct the joint distribution of $X$).

Given a Bayesian Network $\aBayesianNetwork$, let $\pi \in perm(X)$ be a topological order for the DAG of $\aBayesianNetwork$. Then, the probability for some entity $e$ is given by\footnote{From now on, we denote by $X_i$ the random variable associated to feature $x_i$.}

\begin{align}\label{eq:bayesian_probability}
    \Pr[e] = \Pr\left[\bigwedge_{i=1}^n X_i = e(x_i)\right] &= \prod_{i=1}^n \Pr\left[X_{\pi(i)} = e(x_{\pi(i)}) | \bigwedge_{i=1}^{i-1} X_{\pi(i)} = e(x_{\pi(i)})\right]\nonumber \\
    &= \prod_{i=1}^n \Pr\left[X_{\pi(i)} = e(x_{\pi(i)}) | \bigwedge_{x_j \in \parents(x_i)} X_j = e(x_j)\right]
\end{align}

where in the last inequality we used the topological constraints to condition only on the parents of $x_i$.

It was proven in \cite{van2022tractability} that computing the Shapley values for a Naive Bayesian Network is \sharpPhard{} even for trivial models. A Naive Bayesian Network is a Network whose DAG has a star-shape: there is a unique node $x_1$ such that the set of edges is $E = \{(x_1, x_j) : 2 \leq j \leq n\}$ ($x_1$ is a parent of all nodes, and there are no other edges). In this context, the probability of an entity $e$ is computed as given by Equation~\ref{eq:bayesian_probability}:

\begin{align*}
    \Pr[e] = \Pr[X_1 = e(x_1)] \prod_{j=2}^n \Pr[X_j = e(x_j) | X_1 = e(x_1)]
\end{align*}

On the contrary of the usual Shapley values, computing the Assymetric Shapley values (considering the Network itself as the causality DAG) can be done in polynomial time in a wide family of models. More specifically, for any model that allows to compute the normal Shapley Values for the product distribution:

\begin{theorem}
    The Assymetric Shapley Values can be computed in polynomial time for distributions given as a Naive Bayesian Network and for a family of models $\mathcal{F}$ if and only if the Shapley values can be computed for the family $\mathcal{F}$ under an arbitrary product distribution in polynomial time.
\end{theorem}

\begin{proof}
    First, we prove the right-to-left implication. Let $x_1$ be the parent of all the other features in the DAG. We are going to show how to compute $\assym_{M,e,\Pr}(x_j)$ for any $2 \leq j \leq n$ and $\assym_{M,e,\Pr}(x_1)$ independently.

    Observe that the DAG has $n-1!$ topological orders, one for each permutation of the features $\{x_2, \ldots, x_n\}$, and $\pi(x_1) = 1$ for all of them. Then,

    \begin{align}\label{eq:assymetric_for_naive_child}
        \assym_{M,e,\Pr}(X_j) &= \sum_{\pi \in \topo(G)} w(\pi) \left[ \charactheristicFunction_{M,e,\Pr}(\pi_{<j} \cup \{x_j\}) 
        - \charactheristicFunction_{M,e,\Pr}(\pi_{<j}) \right] \nonumber \\
        &= \frac{1}{n-1!} \sum_{\pi \in \perm(\{x_2, \ldots, x_n\})} \left[ \charactheristicFunction_{M,e,\Pr}(\{x_1\} \cup \pi_{<j} \cup {x_j}) - \charactheristicFunction_{M,e,\Pr}(\{x_1\} \cup \pi_{<j}) \right]
    \end{align}

    Observe that once $x_1$ is fixed, the distribution for the variables $x_2,\ldots, x_n$ is a product distribution with $p_{x_j} = P(X_j = 1 | X_1 = e(x_1) )$. For simplicity, let us assume that $e(x_1) = 1$, and consider the product distribution $\Pr'$ defined as

    \begin{align*}
        \Pr\,'[X_i = 1] = p_i = \begin{cases}
            1 & i = 1\\
            \Pr[X_i = 1 | X_1 = e(x_1)] & \text{otherwise}
        \end{cases}
    \end{align*}

    which intuitively is obtained from $\Pr$ by fixing $X_1 = 1$. Whenever $x_1$ is fixed, both distributions $\Pr$ and $\Pr'$ behave in the same way:
    
    \begin{lemma}\label{lemma:valuation_of_prob_function}
    For any $S \subseteq X \setminus \{x_1\}$ it holds that 
    \begin{align*}
        \charFunML_{M,e,\Pr}(\{x_1\} \cup S) = \charFunML_{M,e,\Pr'}(\{x_1\} \cup S) = \charFunML_{M,e,\Pr'}(S) 
    \end{align*}
      
    \end{lemma}

    \begin{proof}
        It follows by plain algebra that
    
        \begin{align}
            \charFunML_{M,e,\Pr}(\{x_1\} \cup S) &= \sum_{e' \in \consistsWith(e,\{x_1\} \cup S)} \Pr[e' | S] M(e') \nonumber \\
            &= \sum_{e' \in \consistsWith(e, \{x_1\} \cup S)} \left( \prod_{\substack{e'(y) = 1 \\ y \notin \{x_1\} \cup S}} p_y \prod_{\substack{e'(y) = 0 \\ y \notin \{x_1\} \cup S}} (1-p_y)\right) M(e')\\
            &= \sum_{e' \in \consistsWith(e, S)} \left( \prod_{\substack{e'(y) = 1 \\ y \notin S}} p_y \prod_{\substack{e'(y) = 0 \\ y \notin S}} (1-p_y)\right) M(e') \nonumber\\
            &= \sum_{e' \in \consistsWith(e, S)} \Pr\,'[e' | S] M(e') \nonumber\\
            &= \charFunML_{M,e,\Pr'}(S) \nonumber
        \end{align}

        where the third equality follows by observing that for all entities $e' \in \consistsWith(e, S)$ such that $e'(x_1) = 0$ it is the case that 
        
        $$\prod_{\substack{e'(y) = 1 \\ y \notin S}} p_y \prod_{\substack{e'(y) = 0 \\ y \notin S}} (1-p_y) = 0$$

        Moreover, Equation~\ref{eq:pr_equals_prprime} is equal to $\charFunML_{M,e,\Pr'}(\{x_1\} \cup S)$.
    \end{proof}

    Using this lemma, we now prove

    \begin{align}\label{eq:relation_between_assym_and_shap_naive_child}
        \assym_{M,e,\Pr} (x_j) = \Shap_{M,e,\Pr'}(x_j)
    \end{align}

    It holds that

    \begin{align*}
        \Shap_{M,e,\Pr'}(x_j) &= \frac{1}{n!} \sum_{\pi \in \perm(X)} \left[ \charFunML_{M,e,\Pr'}(\pi_{<j} \cup \{x_j\}) - \charFunML_{M,e,\Pr'}(\pi_{<j}) \right]\\
        &= \frac{1}{n!} \sum_{\pi \in \perm(X)} \left[ \charFunML_{M,e,\Pr'}(\{x_1\} \cup \pi_{<j} \cup \{x_j\}) - \charFunML_{M,e,\Pr'}(\{x_1\} \cup \pi_{<j}) \right]\\
        &= \frac{n}{n!} \sum_{\pi \in \perm(\{x_2,\ldots,x_n\})} \left[ \charFunML_{M,e,\Pr'}(\{x_1\} \cup \pi_{<j} \cup \{x_j\}) - \charFunML_{M,e,\Pr'}(\{x_1\} \cup \pi_{<j}) \right] \\
        &= \frac{1}{n-1!} \sum_{\pi \in \perm(\{x_2,\ldots,x_n\})} \left[ \charFunML_{M,e,\Pr}(\{x_1\} \cup \pi_{<j} \cup \{x_j\}) - \charFunML_{M,e,\Pr}(\{x_1\} \cup \pi_{<j}) \right]\\
        &= \assym_{M,e,\Pr}(x_j)
    \end{align*}

    where the second and fourth equalities follow by Lemma~\ref{lemma:valuation_of_prob_function}, the last equality by Equation~\ref{eq:assymetric_for_naive_child} and the third one by observing that for each permutation of $\perm(\{x_2,\ldots,x_n\})$ we can build $n$ permutations of $\perm(X)$ by inserting $x_1$ in all possible spots, and that for each one of these permutations the expression inside the summation is the same. Thus, Equation~\ref{eq:relation_between_assym_and_shap_naive_child} shows that computing $\assym_{M,e,\Pr}(x_j)$ reduces to computing the usual Shapley values for a particular independent distribution.

    Now we consider $\assym_{M,e,\Pr}(x_1)$. Note that

    \begin{align*}
        \assym_{M,e,\Pr}(x_1) &= \sum_{\pi \in \topo(G)} \left[ \charFunML_{M,e,\Pr}(\pi_{<1} \cup \{x_1\}) - \charFunML_{M,e,\Pr}(\pi_{<1}) \right]\\
        &= \charFunML_{M,e,\Pr}(\{x_1\}) - \charFunML_{M,e,\Pr}(\emptyset)
    \end{align*}

    since for all permutations the set $\pi_{<1} = \emptyset$. Moreover, we know that $\charFunML_{M,e,\Pr}(\{x_1\}) = \charFunML_{M,e,\Pr'}(\emptyset)$ by Lemma~\ref{lemma:valuation_of_prob_function}, and that

    \begin{align*}
        \charFunML_{M,e,\Pr}(\emptyset) &= \sum_{e' \in \entities(X)} \Pr[e] M(e)\\
        &= \sum_{\substack{e' \in \entities(X) \\ e'(x_1) = 1}} \Pr[e' | e'(x_1) = 1] \Pr[X_1 = 1] M (e') + \sum_{\substack{e' \in \entities(X) \\ e'(x_1) = 0}} \Pr[e' | e'(x_1) = 1] \Pr[X_1 = 0] M (e')\\
        &= \Pr[X_1 = 1] \charFunML_{M,e,\Pr'}(\emptyset) + \Pr[X_1 = 0] \charFunML_{M,e,\Pr''}(\emptyset)
    \end{align*}

    where the distribution $\Pr''$ is the product distribution obtained by fixing $X_1 = 0$ as

    \begin{align*}
        \Pr \, ''[X_i = 1] = \begin{cases}
            0 & i = 0\\
            Pr[X_i = 1 | X_1 = 0] & \text{otherwise}
        \end{cases}
    \end{align*}

    Finally,

    \begin{align*}
        \assym_{M,e,\Pr}(x_1) = (1 - \Pr[X_1 = 1]) \charFunML_{M,e,\Pr'}(\emptyset) - \Pr[X_1 = 0] \charFunML_{M,e,\Pr''}(\emptyset)
    \end{align*}

    and we reduced the problem of computing $\assym_{M,e,\Pr}(x_1)$ to the one of computing the average prediction of the model $M$ for two different independent distributions $\Pr'$ and $\Pr''$. By \cite{van2022tractability}[Theorem 1] it holds that this averages can be computed in polynomial time if and only if the shapley values can be computed in polynomial time for an arbitrary product distribution.

    The left-to-right proof follows by observing that a product distribution is a particular case of a Naive Bayes Distribution in which for any value of the parent $X_1$ the conditional distributions are the same.
    
    
\end{proof}

\subsection{Heuristic for Asymmetric Shapley Values computation}
\label{heuristic_asv_section}