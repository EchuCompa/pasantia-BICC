{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  asvFormula.classesSizes.recursiveFormula import *\n",
    "from asvFormula.bayesianNetworks.bayesianNetwork import *\n",
    "from asvFormula.bayesianNetworks import networkSamplesPath\n",
    "from asvFormula.datasetManipulation import *\n",
    "import pandas as pd\n",
    "from typing import List\n",
    "import numpy as np\n",
    "import random \n",
    "from pgmpy.readwrite import BIFReader\n",
    "from pgmpy.inference import VariableElimination\n",
    "import random\n",
    "import sys,os\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "printEnabled = True\n",
    "def disablePrint():\n",
    "    global printEnabled\n",
    "    if printEnabled:\n",
    "        sys._jupyter_stdout = sys.stdout\n",
    "        sys.stdout = open(os.devnull, 'w')\n",
    "        printEnabled = False\n",
    "\n",
    "def enablePrint():\n",
    "    global printEnabled\n",
    "    printEnabled = True\n",
    "    sys.stdout.close()\n",
    "    sys.stdout = sys._jupyter_stdout\n",
    "\n",
    "def convertDictToCsv(dict, filename):\n",
    "\n",
    "    df = pd.DataFrame.from_dict(dict, orient='index')\n",
    "\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running ASV in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac1077023474ccaadbbdf4e6c10bbcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "random.seed(10)\n",
    "\n",
    "cancerNetworkPath = networkSamplesPath + \"/cancer.bif\"\n",
    "\n",
    "BNmodel = BIFReader(cancerNetworkPath).get_model()\n",
    "BNInference = VariableElimination(BNmodel)\n",
    "\n",
    "variableToPredict = \"Cancer\"\n",
    "treeMaxDepth = 2\n",
    "# Create a BNDatabaseGenerator object from the model\n",
    "dataFromBN = datasetFromBayesianNetwork(BNmodel, 2000)\n",
    "featureColumns = dataFromBN.columns\n",
    "encodingDict, encodedDataset = encodeCategoricalColumns(dataFromBN)\n",
    "dtTreeClassifier = decisionTreeFromDataset(encodedDataset, variableToPredict , treeMaxDepth)\n",
    "dtAsNetwork = obtainNetworkXTreeStructure(dtTreeClassifier, featureColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the Shapley Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Initialize the TreeExplainer\n",
    "explainer = shap.TreeExplainer(dtTreeClassifier)\n",
    "\n",
    "# Compute Shapley values for the test set\n",
    "#shap_values = explainer.shap_values(X_test)\n",
    "\n",
    "# For binary classification, shap_values returns a list with two arrays\n",
    "# We'll use the values corresponding to the positive class (income >50K)\n",
    "#shap_values = shap_values[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ASV Computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asvForFeature(dag : nx.DiGraph, feature : str, instance : pd.Series, model, dataset : pd.DataFrame, feature_distributions : VariableElimination) -> float:\n",
    "    equivalenceClasses = equivalenceClassesFor(dag, \"age\")\n",
    "    asvValue = 0\n",
    "    for equivalenceClass in equivalenceClasses:\n",
    "        classFeaturesOrder = equivalenceClass[0]\n",
    "        classSize = equivalenceClass[1]\n",
    "        asvValue += classSize * asvForEquivalenceClass(classFeaturesOrder, feature, instance, model, dataset, feature_distributions)\n",
    "\n",
    "    return asvValue\n",
    "\n",
    "\n",
    "\n",
    "def asvForEquivalenceClass(classFeaturesOrder : List[str], feature : str, instance : pd.Series, model, dataset : pd.DataFrame, feature_distributions : VariableElimination) -> float:\n",
    "    asvValue = 0\n",
    "    \n",
    "    realFeatures = classFeaturesOrder[:classFeaturesOrder.index(feature)]\n",
    "    \n",
    "    for matchingInstance in matchingInstances(dataset, realFeatures, instance):\n",
    "        asvValue += model.predict(matchingInstance) * probOfInstance(matchingInstance, instance, realFeatures, feature_distributions)\n",
    "    return asvValue\n",
    "\n",
    "\n",
    "def matchingInstances(dataset, realFeatures, instance):\n",
    "    matchingInstances = dataset.copy()\n",
    "    for feature in realFeatures:\n",
    "        matchingInstances = matchingInstances[matchingInstances[feature] == instance[feature]]\n",
    "    return matchingInstances\n",
    "\n",
    "def probOfInstance(matchingInstance : pd.Series, instance : pd.Series, realFeatures : List[str], feature_distributions : VariableElimination) -> float:\n",
    "    \n",
    "    evidence = {realFeature : 'What to dooooo' for realFeature in realFeatures}\n",
    "    \n",
    "    return feature_distributions.query(variables=[instance.name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the ASV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asvForFeature(dtAsNetwork, \"Smoker\", encodedDataset.iloc[0], dtTreeClassifier, encodedDataset, BNInference)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
